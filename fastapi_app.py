from fastapi import FastAPI, Query, Form, Depends, Request
import pandas as pd
from recommendation import recommend_for_all_users, user_object_matrix, user_zscore_matrix, user_similarity, get_username
from utils import load_object_names
import os
import csv
import bcrypt
import logging
import numpy as np
import seaborn as sns
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
from matplotlib.patches import Ellipse
from io import BytesIO
import base64
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from fastapi.responses import RedirectResponse, HTMLResponse, JSONResponse
from fastapi.templating import Jinja2Templates
from starlette.requests import Request
from starlette.middleware.sessions import SessionMiddleware
from fastapi.staticfiles import StaticFiles
from recommendation import get_recommendations_for_user
from dotenv import load_dotenv
import asyncio
from sklearn.metrics.pairwise import cosine_similarity
from fastapi import APIRouter
import urllib.parse
from scipy.stats import chi2



# .envãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
load_dotenv()

app = FastAPI()

_cached_merged_df = None
_cached_object_id_to_name = None
_cached_user_dict = None
_cached_recommend_df = None

@app.api_route("/", methods=["GET", "HEAD"])
async def login_page(request: Request, error_message: str = ""):
    """ãƒ­ã‚°ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤ºï¼ˆGETãŠã‚ˆã³HEADå¯¾å¿œï¼‰"""
    user = request.session.get("user_id")
    if user:
        return RedirectResponse(url=f"/rating", status_code=303)
    return templates.TemplateResponse("index.html", {"request": request, "error_message": error_message})

# âœ… ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‚­ãƒ¼ã‚’å–å¾—ï¼ˆè¨­å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ï¼‰
SECRET_KEY = os.getenv("SESSION_SECRET_KEY", "default-secret-key")
app.add_middleware(SessionMiddleware, secret_key=SECRET_KEY)

# ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆè¨­å®š
templates = Jinja2Templates(directory="templates")

# users.csv ã®ãƒ‘ã‚¹ã‚’æ˜ç¤ºçš„ã«æŒ‡å®š
USERS_FILE = "/opt/render/project/src/users.csv"
OBJECTS_FILE = "/opt/render/project/src/objects.csv"
RATINGS_FILE = "/opt/render/project/src/ratings.csv"


# âœ… `objects.csv` ã®èª­ã¿è¾¼ã¿ï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãï¼‰
object_dict = {}
try:
    objects_df = pd.read_csv(OBJECTS_FILE, encoding="utf-8-sig", dtype={"object_id": str})
    object_dict = dict(zip(objects_df["object_id"].astype(str), objects_df["object_name"].fillna("Unknown")))
except FileNotFoundError:
    logging.warning(f"Warning: {OBJECTS_FILE} not found. Using empty object dictionary.")
    object_dict = {}

# `ratings.csv` ã®å­˜åœ¨ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’åˆæœŸåŒ–
if os.path.exists(RATINGS_FILE):
    ratings_df = pd.read_csv(RATINGS_FILE, encoding="utf-8-sig", dtype={"user_id": str, "object_id": str})
    ratings_df["rating"] = pd.to_numeric(ratings_df["rating"], errors="coerce")  # æ•°å€¤å¤‰æ›ï¼ˆã‚¨ãƒ©ãƒ¼æ™‚ã¯ NaNï¼‰

    # `object_id` ã‚’æ˜ç¤ºçš„ã« str ã«å¤‰æ›
    ratings_df["object_id"] = ratings_df["object_id"].astype(str)

    # `object_id` ã‚’ `object_name` ã«å¤‰æ›ï¼ˆobject_id ãŒ `object_dict` ã«ã‚ã‚‹å ´åˆã®ã¿ï¼‰
    if not ratings_df.empty:
        ratings_df["object_name"] = ratings_df["object_id"].map(object_dict)
        print("ğŸ” `ratings_df` ã® `object_name` ã®ã‚µãƒ³ãƒ—ãƒ«:\n", ratings_df.head())  # ãƒ‡ãƒãƒƒã‚°ç”¨å‡ºåŠ›
else:
    # `ratings.csv` ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
    with open(RATINGS_FILE, "w", newline="", encoding="utf-8-sig") as file:
        writer = csv.writer(file)
        writer.writerow(["user_id", "object_id", "rating"])  # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è¿½åŠ 
    ratings_df = pd.DataFrame(columns=["user_id", "object_id", "rating"])  # ç©ºã®DataFrameã‚’ä½œæˆ

app.mount("/static", StaticFiles(directory="static", html=True), name="static")

def update_user_similarity():
    global user_similarity

    # `user_object_matrix` ã‚’å–å¾—ã—ã€NaN ã‚’ 0 ã«ç½®ãæ›ãˆ
    user_object_matrix_filled = user_object_matrix.fillna(0)

    # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®—
    new_similarity_matrix = pd.DataFrame(
        cosine_similarity(user_object_matrix_filled),
        index=user_object_matrix_filled.index,
        columns=user_object_matrix_filled.index
    )

    # `user_similarity` ã‚’æ›´æ–°
    user_similarity = new_similarity_matrix

@app.get("/routes")
async def get_routes():
    return [{"path": route.path, "name": route.name} for route in app.router.routes]

@app.get("/")
def show_login_page(request: Request, error_message: str = ""):
    """ãƒ­ã‚°ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤º"""
    user = request.session.get("user")
    return templates.TemplateResponse("index.html", {"request": request, "error_message": error_message, "messages": []})

@app.post("/login")
async def login(request: Request, username: str = Form(...), password: str = Form(...)):
    """ ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ­ã‚°ã‚¤ãƒ³å‡¦ç† """

    # `users.csv` ãŒå­˜åœ¨ã—ãªã„å ´åˆã€ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
    if not os.path.exists(USERS_FILE):
        return templates.TemplateResponse("index.html", {
            "request": request,
            "error_message": "ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
        })

    # `users.csv` ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€
    with open(USERS_FILE, "r", newline="", encoding="utf-8") as file:
        reader = csv.reader(file)
        next(reader, None)  # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ã‚¹ã‚­ãƒƒãƒ—

        for row in reader:
            stored_user_id, stored_username, stored_password_hash = row

            # ğŸ” ãƒ¦ãƒ¼ã‚¶ãƒ¼åãŒä¸€è‡´ã™ã‚‹ã‹ç¢ºèª
            if stored_username == username:
                # ğŸ” ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒä¸€è‡´ã™ã‚‹ã‹ç¢ºèª
                if bcrypt.checkpw(password.encode(), stored_password_hash.encode()):
                    request.session["username"] = username
                    request.session["user_id"] = stored_user_id

                    return RedirectResponse(url="/rating", status_code=303)

                return templates.TemplateResponse("index.html", {
                    "request": request,
                    "error_message": "ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé–“é•ã£ã¦ã„ã¾ã™ã€‚"
                })

    return templates.TemplateResponse("index.html", {
        "request": request,
        "error_message": "ãƒ¦ãƒ¼ã‚¶ãƒ¼åãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚"
    })

router = APIRouter()

@router.post("/logout")
async def logout(request: Request):
    """ ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ã‚¯ãƒªã‚¢ã—ã€ã‚¯ãƒƒã‚­ãƒ¼ã‚’å‰Šé™¤ã—ã¦ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ """
    request.session.clear()  # âœ… ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’å‰Šé™¤
    response = RedirectResponse(url="/index", status_code=303)
    response.delete_cookie("session")  # âœ… ã‚¯ãƒƒã‚­ãƒ¼ã‚‚å‰Šé™¤
    return response

@app.get("/index")
async def show_index_page(request: Request):
    """ æ˜ç¤ºçš„ã« index.html ã‚’è¡¨ç¤ºã™ã‚‹ãƒ«ãƒ¼ãƒˆ """
    return templates.TemplateResponse("index.html", {"request": request})


@app.get("/objects")
def get_objects():
    """ãƒ¬ã‚¹ãƒˆãƒ©ãƒ³ä¸€è¦§ã‚’å–å¾—"""
    return {"object_names": list(object_dict.values())}  # API ã§ã¯ãƒªã‚¹ãƒˆã¨ã—ã¦è¿”ã™

@app.get("/recommend/{user_id}")
def get_recommendations(request: Request, user_id: str):
    """ç‰¹å®šã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«å¯¾ã™ã‚‹æ¨è–¦çµæœã‚’å–å¾—"""
    user = request.session.get("user_id")
    if not user or user != user_id:
        return RedirectResponse(url="/", status_code=303)
    
    # å…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ¨è–¦ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰
    recommendation_df, user_similarity_data = recommend_for_all_users()

    # æŒ‡å®šã—ãŸ `user_id` ã«å¯¾ã™ã‚‹æ¨è–¦ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    user_recommendations = recommendation_df[recommendation_df["user_id"] == user_id]

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼åã‚’å–å¾—
    username = get_username(user_id)

    # æ¨è–¦ãƒªã‚¹ãƒˆã‚’è¾æ›¸ã«å¤‰æ›
    recommendations = [
        {
            "object_id": str(row["object_id"]),
            "object_name": object_dict.get(str(row["object_id"]), "ä¸æ˜"),
            "recommendation_score": round(row["recommendation_score"], 2)  # 0.25 ä»¥ä¸Šã®ã‚‚ã®ã‚’è€ƒæ…®
        }
        for _, row in user_recommendations.iterrows()
        if pd.notna(row["recommendation_score"])
    ]

    return templates.TemplateResponse("recommendations.html", {
        "request": request,
        "username": username,
        "recommendations": recommendations,
        "has_similar_users": len(recommendations) > 0
    })

# ãƒ¦ãƒ¼ã‚¶ãƒ¼åã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯é–¢æ•°
def is_username_taken(username: str) -> bool:
    """ ãƒ¦ãƒ¼ã‚¶ãƒ¼åãŒæ—¢ã«ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª """
    if not os.path.exists(USERS_FILE):
        return False  # ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„å ´åˆã¯å­˜åœ¨ã—ãªã„
    
    with open(USERS_FILE, "r", newline="", encoding="utf-8") as file:
        reader = csv.reader(file)
        for row in reader:
            if row and row[1] == username:
                return True  # æ—¢ã«å­˜åœ¨ã™ã‚‹
    return False  # å­˜åœ¨ã—ãªã„

# ãƒ¦ãƒ¼ã‚¶ãƒ¼åã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯APIï¼ˆãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ç”¨ï¼‰
@app.get("/check_username")
def check_username(username: str = Query(...)):
    """ ãƒ¦ãƒ¼ã‚¶ãƒ¼åã®é‡è¤‡ãƒã‚§ãƒƒã‚¯API """
    return {"exists": is_username_taken(username)}

@app.get("/register")
async def show_register_page(request: Request):
    """æ–°è¦ç™»éŒ²ãƒšãƒ¼ã‚¸ã‚’é–‹ãéš›ã«ãƒ­ã‚°ã‚¢ã‚¦ãƒˆã™ã‚‹"""
    request.session.clear()  # âœ… ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’å‰Šé™¤ã—ã¦ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ
    response = templates.TemplateResponse("register.html", {"request": request})
    response.delete_cookie("session")  # âœ… ã‚¯ãƒƒã‚­ãƒ¼ã‚‚å‰Šé™¤
    return response

# æ–°è¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™»éŒ²å‡¦ç†
@app.post("/register")
async def register_user(request: Request, username: str = Form(...), password: str = Form(...)):
    """ æ–°è¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™»éŒ²å‡¦ç† """
    if not os.path.exists(USERS_FILE):
        with open(USERS_FILE, "w", newline="", encoding="utf-8") as file:
            writer = csv.writer(file)
            writer.writerow(["user_id", "username", "password_hash"])  # ãƒ˜ãƒƒãƒ€ãƒ¼è¿½åŠ 

    # æ—¢å­˜ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’å–å¾—
    existing_users = []
    with open(USERS_FILE, "r", newline="", encoding="utf-8") as file:
        reader = csv.reader(file)
        next(reader, None)  # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ã‚¹ã‚­ãƒƒãƒ—
        for row in reader:
            # ä¸‡ãŒä¸€è¡ŒãŒä¸æ­£ãªå ´åˆã®å¯¾ç­–ã¨ã—ã¦é•·ã•ãƒã‚§ãƒƒã‚¯
            if len(row) >= 2:
                existing_users.append(row[1])

    if username in existing_users:
        return templates.TemplateResponse("register.html", {
            "request": request,
            "error_message": "ã“ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼åã¯æ—¢ã«ç™»éŒ²ã•ã‚Œã¦ã„ã¾ã™ã€‚"
        })

    user_id = str(len(existing_users) + 1)
    hashed_password = bcrypt.hashpw(password.encode(), bcrypt.gensalt()).decode()

    # æœ«å°¾ã«æ”¹è¡ŒãŒã‚ã‚‹ã‹ã‚’ãƒã‚¤ãƒŠãƒªãƒ¢ãƒ¼ãƒ‰ã§ç¢ºèª
    newline_needed = False
    if os.path.getsize(USERS_FILE) > 0:
        with open(USERS_FILE, "rb") as file:
            file.seek(-1, os.SEEK_END)
            last_byte = file.read(1)
            if last_byte != b'\n':
                newline_needed = True

    with open(USERS_FILE, "a", newline="", encoding="utf-8") as file:
        if newline_needed:
            file.write("\n")
        writer = csv.writer(file)
        writer.writerow([user_id, username, hashed_password])
    
    _cached_merged_df, _cached_object_id_to_name, _cached_recommend_df, _cached_user_dict = create_merged_df()

    return RedirectResponse(url="/", status_code=303)

def is_object_exists(object_name: str) -> bool:
    """ æŒ‡å®šã•ã‚ŒãŸè©•ä¾¡å¯¾è±¡ãŒ `objects.csv` ã«æ—¢ã«å­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ """
    if not os.path.exists(OBJECTS_FILE):
        return False  # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã‘ã‚Œã°ã€è©•ä¾¡å¯¾è±¡ã¯å­˜åœ¨ã—ãªã„
    
    with open(OBJECTS_FILE, "r", newline="", encoding="utf-8-sig") as file:
        reader = csv.reader(file)
        existing_objects = {row[0] for row in reader if row}  # æ—¢å­˜ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆåã‚’å–å¾—
    
    return object_name in existing_objects

@app.get("/add_objects", response_class=HTMLResponse)
async def show_add_objects_page(request: Request, success: bool = False, message: str = ""):
    messages = [message] if success and message else []
    return templates.TemplateResponse(
        "add_objects.html",
        {
            "request": request,
            "messages": messages  # âœ… messages ãŒæœªå®šç¾©ã®å ´åˆã€ç©ºãƒªã‚¹ãƒˆã‚’æ¸¡ã™
        }
    )

@app.post("/add_objects")
async def add_objects(request: Request, object_names: str = Form(...)):
    """ æ–°ã—ã„è©•ä¾¡å¯¾è±¡ï¼ˆé£²é£Ÿåº—ï¼‰ã‚’ `objects.csv` ã«è¿½åŠ  """

    #  ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§è¤‡æ•°ã®é£²é£Ÿåº—åã‚’ãƒªã‚¹ãƒˆã«å¤‰æ›
    new_objects = [name.strip() for name in object_names.split(",") if name.strip()]

    if not new_objects:
        return templates.TemplateResponse("add_objects.html", {
            "request": request,
            "error_message": "è©•ä¾¡å¯¾è±¡ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"
        })

    #  ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã‘ã‚Œã°ä½œæˆ
    if not os.path.exists(OBJECTS_FILE):
        with open(OBJECTS_FILE, "w", newline="", encoding="utf-8-sig") as file:
            writer = csv.writer(file)
            writer.writerow(["object_id", "object_name"])  # ãƒ˜ãƒƒãƒ€ãƒ¼è¿½åŠ 

    #  æ—¢å­˜ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å–å¾—ï¼ˆè¾æ›¸å½¢å¼: {object_name: object_id}ï¼‰
    existing_objects = {}
    with open(OBJECTS_FILE, "r", newline="", encoding="utf-8-sig") as file:
        reader = csv.reader(file)
        next(reader, None)  # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ã‚¹ã‚­ãƒƒãƒ—
        for row in reader:
            if len(row) == 2:
                existing_objects[row[1]] = str(row[0])  # {object_name: object_id}

    #  è¿½åŠ ã™ã‚‹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ãƒªã‚¹ãƒˆã‚’ä½œæˆ
    added_objects = []
    next_id = str(len(existing_objects) + 1) 
    for obj in new_objects:
        if obj not in existing_objects:  # é‡è¤‡ã—ãªã„å ´åˆã®ã¿è¿½åŠ 
            added_objects.append((next_id, obj))
            next_id = str(int(next_id) + 1)  # object_id ã‚’å¢—ã‚„ã™

    if not added_objects:
        return templates.TemplateResponse("add_objects.html", {
            "request": request,
            "error_message": "ã™ã¹ã¦ã®è©•ä¾¡å¯¾è±¡ãŒæ—¢ã«ç™»éŒ²ã•ã‚Œã¦ã„ã¾ã™ã€‚"
        })

    #  CSV ã«æ–°ã—ã„è©•ä¾¡å¯¾è±¡ã‚’è¿½åŠ 
    with open(OBJECTS_FILE, "a", newline="", encoding="utf-8-sig") as file:
        writer = csv.writer(file)
        writer.writerows(added_objects)  # ã¾ã¨ã‚ã¦æ›¸ãè¾¼ã‚€

    _cached_merged_df, _cached_object_id_to_name, _cached_recommend_df, _cached_user_dict = create_merged_df()

    # âœ… ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’URLã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ã—ã¦æ¸¡ã™ï¼ˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰å‡¦ç†ï¼‰
    message = urllib.parse.quote("è©•ä¾¡å¯¾è±¡ãŒè¿½åŠ ã•ã‚Œã¾ã—ãŸï¼")

    # âœ… ç™»éŒ²æˆåŠŸå¾Œã« `messages` ã‚’ã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ã—ã¦æ¸¡ã™
    return RedirectResponse(url=f"/add_objects?success=true&message={message}", status_code=303)

@app.get("/rating")
async def show_rating_page(request: Request):
    """è©•ä¾¡ãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤º"""

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ã„ãªã„å ´åˆã¯ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆ
    username = request.session.get("username")
    user_id = request.session.get("user_id")
    if not username:
        return RedirectResponse(url="/", status_code=303)

    # `user_id` ã‚’æ–‡å­—åˆ—ã¨ã—ã¦çµ±ä¸€ï¼ˆ`ratings.csv` ã®ãƒ‡ãƒ¼ã‚¿å‹ä¸ä¸€è‡´å¯¾ç­–ï¼‰
    user_id = str(user_id)

    # objects.csv ã‹ã‚‰è©•ä¾¡å¯¾è±¡ã‚’å–å¾—ï¼ˆobject_idã®é™é †ã«ã‚½ãƒ¼ãƒˆï¼‰
    objects = {}
    if os.path.exists(OBJECTS_FILE):
        objects_df = pd.read_csv(OBJECTS_FILE, encoding="utf-8-sig")

        # object_id ã‚’æ•´æ•°å‹ã«å¤‰æ›ã—ã¦é™é †ã‚½ãƒ¼ãƒˆ
        objects_df["object_id"] = objects_df["object_id"].astype(str)
        objects_df["object_id"] = objects_df["object_id"].astype(int)

        objects_df = objects_df.sort_values("object_id", ascending=False)
        objects_df["object_id"] = objects_df["object_id"].astype(str)

        # object_id ã‚’ã‚­ãƒ¼ã€object_name ã‚’å€¤ã¨ã™ã‚‹è¾æ›¸ã«å¤‰æ›
        objects = dict(zip(objects_df["object_id"], objects_df["object_name"]))

    # ratings.csv ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
    if not os.path.exists(RATINGS_FILE):
        with open(RATINGS_FILE, "w", newline="", encoding="utf-8-sig") as file:
            writer = csv.writer(file)
            writer.writerow(["user_id", "object_id", "rating"])  # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è¿½åŠ 

    # `ratings.csv` ã‹ã‚‰æœ€æ–°ã®è©•ä¾¡ã®ã¿å–å¾—
    past_ratings = {object_id: None for object_id in objects.keys()}  # æœªè©•ä¾¡ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¯ None ã«ã™ã‚‹
    if os.path.exists(RATINGS_FILE) and os.stat(RATINGS_FILE).st_size > 0:
        df = pd.read_csv(RATINGS_FILE, encoding="utf-8-sig", dtype={"user_id": str, "object_id": str})

        # æœ€æ–°ã®è©•ä¾¡ã®ã¿å–å¾—ï¼ˆ`user_id` ãŒæ–‡å­—åˆ—ã«ãªã£ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªï¼‰
        latest_ratings = (df[df["user_id"] == user_id].sort_values(by=["user_id", "object_id", "rating"]).groupby("object_id")["rating"].last().to_dict())

        # `past_ratings` ã«æœ€æ–°ã®è©•ä¾¡ã‚’åæ˜ 
        for object_id in objects.keys():
            if object_id in latest_ratings:
                past_ratings[object_id] = latest_ratings[object_id]  # è©•ä¾¡æ¸ˆã¿ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¯æœ€æ–°ã®è©•ä¾¡ã‚’è¨­å®š

    # **è©•ä¾¡å€¤ã®ãƒªã‚¹ãƒˆ**
    rating_values = ["", "1", "2", "3", "4", "5"]
    rating_labels = ["?", "1", "2", "3", "4", "5"]

    # **Python å´ã§ `zip()` ã‚’ä½¿ã£ã¦ãƒªã‚¹ãƒˆåŒ–**
    rating_pairs = list(zip(rating_values, rating_labels))
    
    return templates.TemplateResponse("rating.html", {
        "request": request,
        "username": username,
        "objects": objects,  # object_id â†’ object_name ã«å¤‰æ›
        "past_ratings": past_ratings,  # æœ€æ–°ã®è©•ä¾¡ã‚’è¡¨ç¤º
        "rating_pairs": rating_pairs,  # è©•ä¾¡å€¤ã¨è¡¨ç¤ºãƒ©ãƒ™ãƒ«ã®ãƒšã‚¢
    })


@app.post("/submit_ratings")
async def submit_ratings(request: Request):
    """è©•ä¾¡ã‚’ ratings.csv ã«æ›´æ–°"""

    logging.info("submit_ratings() called")  # âœ… ãƒ­ã‚°ã‚’è¿½åŠ 
    form_data = await request.form()
    ratings = {key.replace("ratings[", "").replace("]", ""): value for key, value in form_data.items() if "ratings[" in key}
    delete_flags = {key.replace("delete_", ""): value for key, value in form_data.items() if key.startswith("delete_")}

    if not ratings and not delete_flags:
        logging.warning("No ratings provided")  # âœ… ãƒ­ã‚°ã‚’è¿½åŠ 
        return JSONResponse(content={"detail": "No ratings provided"}, status_code=400)

    user_id = request.session["user_id"]
    logging.info(f"Processing ratings for user_id: {user_id}")  # âœ… ãƒ­ã‚°ã‚’è¿½åŠ 

    # `ratings.csv` ã‚’ DataFrame ã¨ã—ã¦èª­ã¿è¾¼ã‚€
    if os.path.exists(RATINGS_FILE):
        df = pd.read_csv(RATINGS_FILE, encoding="utf-8-sig")
    else:
        df = pd.DataFrame(columns=["user_id", "object_id", "rating"])
    
    # ç¢ºå®Ÿã« user_id ã‚’ int å‹ã«å¤‰æ›
    if not df.empty:
        df["user_id"] = df["user_id"].astype(int)


    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®éå»ã®è©•ä¾¡ã‚’å‰Šé™¤ï¼ˆæ›´æ–°ã™ã‚‹ãŸã‚ï¼‰
    df = df[df["user_id"] != int(user_id)]

    # å‰Šé™¤ãƒ•ãƒ©ã‚°ãŒ `true` ã®ã‚‚ã®ã¯ã€æ–°ã—ã„è©•ä¾¡ã«è¿½åŠ ã—ãªã„
    new_ratings = pd.DataFrame(
        [[user_id, object_id, int(rating)] for object_id, rating in ratings.items() if rating and delete_flags.get(object_id) != "true"],
        columns=["user_id", "object_id", "rating"]
    )

    # æœ€æ–°ã®ãƒ‡ãƒ¼ã‚¿ã§ `ratings.csv` ã‚’ä¸Šæ›¸ã
    df = pd.concat([df, new_ratings], ignore_index=True).drop_duplicates() 

    try:
        df.to_csv(RATINGS_FILE, index=False, encoding="utf-8-sig")
        logging.info("ratings.csv successfully updated")  # âœ… ãƒ­ã‚°ã‚’è¿½åŠ 
    except Exception as e:
        logging.error(f"Error writing to ratings.csv: {e}")  # âœ… ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’è¿½åŠ 
        return JSONResponse(content={"detail": "Failed to update ratings.csv"}, status_code=500)
    
    # æ›¸ãè¾¼ã¿å¾Œã«çŸ­ã„é…å»¶ã‚’å…¥ã‚Œã‚‹
    await asyncio.sleep(0.1)
    # æ›´æ–°ã‚’åæ˜ 
    try:
        await update_ratings_no_reload()
        logging.info("update_ratings_no_reload() completed")  # âœ… ãƒ­ã‚°ã‚’è¿½åŠ 
    except Exception as e:
        logging.error(f"Error in update_ratings_no_reload(): {e}")  # âœ… ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’è¿½åŠ 
        return JSONResponse(content={"detail": "Failed to update ratings"}, status_code=500)

    logging.info("Redirecting to recommendations")  # âœ… ãƒ­ã‚°ã‚’è¿½åŠ 
    return RedirectResponse(url="/recommendations", status_code=303)


async def update_ratings_no_reload():
    """`ratings.csv` ã‚’æœ€æ–°ã®ãƒ‡ãƒ¼ã‚¿ã«æ›´æ–°"""
    global _cached_merged_df, _cached_object_id_to_name, _cached_user_dict, _cached_recommend_df

    try:
        _cached_merged_df, _cached_object_id_to_name, _cached_recommend_df, _cached_user_dict = create_merged_df()
        logging.info("Cache successfully updated in update_ratings_no_reload()")
    except Exception as e:
        logging.error(f"Error in update_ratings_no_reload(): {e}")
        raise

@app.get("/recommendations")
async def recommendations_page(request: Request):
    """ãŠã™ã™ã‚çµæœã‚’è¡¨ç¤º"""
    username = request.session.get("username")
    user_id = request.session.get("user_id")
    if not username:
        return RedirectResponse(url="/", status_code=303)
    
    # âœ… `copy()` ã‚’ä½¿ã£ã¦ã‚¹ãƒ©ã‚¤ã‚¹ã®å½±éŸ¿ã‚’é˜²ã
    recommendations_df, user_similarity_data = recommend_for_all_users()  # âœ… ã‚¿ãƒ—ãƒ«ã‚’å±•é–‹ã—ã¦ä»£å…¥
    user_recommendations = recommendations_df[recommendations_df["user_id"] == user_id].copy()

    # âœ… `object_id` ã‹ã‚‰ `object_name` ã‚’å–å¾—
    user_recommendations["object_name"] = user_recommendations["object_id"].map(object_dict)

    # âœ… `recommendation_score` ã‚’å°æ•°ç‚¹ä»¥ä¸‹2æ¡ã«ä¸¸ã‚ã‚‹
    user_recommendations["recommendation_score"] = user_recommendations["recommendation_score"].round(2)

    return templates.TemplateResponse("recommendations.html", {
        "request": request,
        "username": username,
        "recommendations": user_recommendations.to_dict(orient="records"),
    })


def categorize_recommendation(score):
    try:
        score_val = float(score)
    except (ValueError, TypeError):
        return "-"
    if score_val < 0.25:
        return "-"
    elif score_val >= 0.75:
        return "â˜…â˜…â˜…"
    elif score_val >= 0.5:
        return "â˜…â˜…"
    elif score_val >= 0.25:
        return "â˜…"
    
def format_cell(row):
    # rating ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    try:
        rating_val = float(row["rating"])
        rating = f"{rating_val:.1f}"
    except (ValueError, TypeError):
        rating = str(row["rating"])
        
    # z_score ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    try:
        z_val = float(row["z_score"])
        z_score = f"{z_val:.2f}"
    except (ValueError, TypeError):
        z_score = str(row["z_score"])
        
    # recommendation_score ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    try:
        rec_val = float(row["recommendation_score"])
        rec_score = f"{rec_val:.2f}"
    except (ValueError, TypeError):
        rec_score = str(row["recommendation_score"])

    stars = categorize_recommendation(row["recommendation_score"])
    return f"R: {rating}\nZ: {z_score}\nRS: {rec_score}\n{stars}"


def create_merged_df():
    global _cached_merged_df, _cached_object_id_to_name, _cached_user_dict, _cached_recommend_df, user_similarity

    # --- æ¨è–¦ãƒ‡ãƒ¼ã‚¿ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼é¡ä¼¼åº¦ã®è¨ˆç®— ---
    recommend_df, computed_user_similarity = recommend_for_all_users()
    # ã“ã“ã§ã‚°ãƒ­ãƒ¼ãƒãƒ«ã®user_similarityã‚‚æ›´æ–°ã™ã‚‹
    user_similarity = computed_user_similarity
    # --- ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ ---
    users = pd.read_csv(USERS_FILE, encoding="utf-8-sig") if os.path.exists(USERS_FILE) else pd.DataFrame(columns=["user_id", "username"])
    objects = pd.read_csv(OBJECTS_FILE, encoding="utf-8-sig") if os.path.exists(OBJECTS_FILE) else pd.DataFrame(columns=["object_id", "object_name"])
    ratings = pd.read_csv(RATINGS_FILE, encoding="utf-8-sig") if os.path.exists(RATINGS_FILE) else pd.DataFrame(columns=["user_id", "object_id", "rating"])

    # âœ… `user_id` ã‚’ã™ã¹ã¦ `str` ã«çµ±ä¸€
    users["user_id"] = users["user_id"].astype(str)
    ratings["user_id"] = ratings["user_id"].astype(str)
    ratings["object_id"] = ratings["object_id"].astype(str)
    objects["object_id"] = objects["object_id"].astype(str)

    # --- ãƒ¦ãƒ¼ã‚¶ãƒ¼ID, ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆID ã®ãƒãƒƒãƒ”ãƒ³ã‚° ---
    _cached_user_dict = dict(zip(users["user_id"], users["username"]))
    object_dict_local = dict(zip(objects["object_id"], objects["object_name"]))
    ratings["username"] = ratings["user_id"].map(_cached_user_dict)
    ratings["object_name"] = ratings["object_id"].map(object_dict_local)

    recommend_df["user_id"] = recommend_df["user_id"].astype(str)
    recommend_df["object_id"] = recommend_df["object_id"].astype(str)
    recommend_df["recommendation_score"] = recommend_df["recommendation_score"].astype(float)

    # --- `ratings` ãŒç©ºãªã‚‰é©åˆ‡ãªãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’è¨­å®š ---
    if ratings.empty:
        ratings = pd.DataFrame(columns=["user_id", "object_id", "rating"])

    # --- ãƒ¦ãƒ¼ã‚¶ãƒ¼ Ã— ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ”ãƒœãƒƒãƒˆãƒ†ãƒ¼ãƒ–ãƒ« ---
    user_object_matrix_df = ratings.pivot(index="user_id", columns="object_id", values="rating").reset_index()

    # --- user_zscore_matrix ã®è¨ˆç®— ---
    user_zscore_matrix_df = user_object_matrix_df.copy()
    numeric_cols = user_zscore_matrix_df.columns.drop("user_id", errors="ignore")
    user_zscore_matrix_df[numeric_cols] = user_zscore_matrix_df[numeric_cols].apply(
        lambda x: (x - x.mean()) / (x.std() if x.std() != 0 else 1), axis=1
    )

    # --- `user_ratings` ã‚’ä½œæˆ ---
    user_ratings = user_object_matrix_df.melt(id_vars=["user_id"], var_name="object_id", value_name="rating")

    # --- `user_z_scores` ã‚’ä½œæˆ ---
    user_z_scores = user_zscore_matrix_df.melt(id_vars=["user_id"], var_name="object_id", value_name="z_score")

    # --- `merged_df` ã‚’ä½œæˆ ---
    merged_df = pd.merge(user_ratings, user_z_scores, on=["user_id", "object_id"], how="outer")

    # --- `recommend_df` ã¨ã®çµåˆ ---
    merged_df = pd.merge(merged_df, recommend_df, on=["user_id", "object_id"], how="left")


    # --- `recommendation_score` ã®æ¬ æå€¤ã‚’åŸ‹ã‚ã‚‹ ---
    if "recommendation_score" in merged_df.columns:
        merged_df["recommendation_score"] = merged_df["recommendation_score"].fillna(0).astype(float)
    else:
        print("âŒ `recommendation_score` ã‚«ãƒ©ãƒ ãŒ `merged_df` ã«ã‚ã‚Šã¾ã›ã‚“ã€‚ãƒãƒ¼ã‚¸ã®å‡¦ç†ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

    # --- æ¬ æå€¤ã®å‡¦ç† ---
    merged_df["rating"] = merged_df["rating"].fillna("-")
    merged_df["z_score"] = merged_df["z_score"].fillna("-")

    merged_df["username"] = merged_df["user_id"].map(_cached_user_dict)
    merged_df["object_name"] = merged_df["object_id"].map(object_dict_local)

    merged_df["cell_info"] = merged_df.apply(format_cell, axis=1)

    # --- object_id â†’ object_name ã®è¾æ›¸ä½œæˆ ---
    object_id_to_name = dict(zip(objects["object_id"], objects["object_name"].fillna("Unknown")))

    # merged_df ã®ç”Ÿæˆå‡¦ç†ã®æœ€å¾Œã§
    _cached_merged_df = merged_df
    _cached_object_id_to_name = object_id_to_name
    _cached_recommend_df = recommend_df
    
    print("ğŸ” `merged_df` ã®å…ˆé ­:\n", merged_df.head())

    return merged_df, object_id_to_name, recommend_df, _cached_user_dict

@app.get("/admin_reviews", response_class=HTMLResponse)
async def admin_reviews(request: Request):
    global _cached_merged_df, _cached_object_id_to_name, _cached_recommend_df, _cached_user_dict, user_similarity

    _cached_merged_df, _cached_object_id_to_name, _cached_recommend_df, _cached_user_dict = create_merged_df()
    
    if user_similarity is None or user_similarity.empty:
        return HTMLResponse(content="ãƒ¦ãƒ¼ã‚¶ãƒ¼é¡ä¼¼åº¦ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“", status_code=500)
    
    # ã‚°ãƒ©ãƒ•ç”Ÿæˆã‚„ãƒ”ãƒœãƒƒãƒˆãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆãªã©ã‚’ã¾ã¨ã‚ã¦å®Ÿè¡Œ
    (
        heatmap_base64,
        similarity_hist_base64,
        cluster_df,
        cluster_plot_base64,
        recommendation_hist_base64,
        pivot_compact,
        object_name_cols
    ) = update_heatmap()

    # âœ… ã‚¯ãƒ©ã‚¹ã‚¿è¡¨ã®2ç¨®é¡ã®ä¸¦ã³æ›¿ãˆ
    cluster_sorted_by_username = cluster_df.sort_values(
        ["username"], key=lambda x: x.str.casefold()
    )
    cluster_sorted_by_cluster = cluster_df.sort_values(
        ["cluster", "username"], 
        key=lambda x: x.str.casefold() if x.name == "username" else x
    )

    # æœ€å¾Œã«ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’è¿”ã™
    return templates.TemplateResponse(
        "admin_reviews.html",
        {
            "request": request,
            "pivot_table": pivot_compact.to_dict(orient="records"),
            "column_names": object_name_cols,
            "heatmap_base64": heatmap_base64,
            "similarity_hist_base64": similarity_hist_base64,
            "cluster_sorted_by_username": cluster_sorted_by_username.to_dict(orient="records"),
            "cluster_sorted_by_cluster": cluster_sorted_by_cluster.to_dict(orient="records"),
            "cluster_plot_base64": cluster_plot_base64,
            "recommendation_hist_base64": recommendation_hist_base64
        },
        headers={"Cache-Control": "no-cache, no-store, must-revalidate"}
    )

# =============================
# ã‚°ãƒ©ãƒ•ãªã©ã‚’ç”Ÿæˆã™ã‚‹è£œåŠ©é–¢æ•°
# =============================
def update_heatmap():
    """
    update_heatmap() ã¯ã€admin_reviews() å†…ã§åˆ©ç”¨ã™ã‚‹å¯è¦–åŒ–å‡¦ç†ã‚’ã¾ã¨ã‚ãŸé–¢æ•°ã€‚
    ã‚°ãƒ©ãƒ•ã‚„ãƒ”ãƒœãƒƒãƒˆãƒ†ãƒ¼ãƒ–ãƒ«ãªã©ã‚’ä½œã‚Šã€Base64æ–‡å­—åˆ—ã‚„DataFrameã‚’è¿”ã™ã€‚
    """
    global user_similarity, _cached_merged_df, _cached_object_id_to_name, _cached_user_dict, _cached_recommend_df

    # ========== ãƒ”ãƒœãƒƒãƒˆãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆ ==========
    # _cached_merged_df ã‹ã‚‰ pivot_compact ã‚’ä½œã‚‹
    _cached_merged_df["user_id"] = _cached_merged_df["user_id"].astype(str)
    _cached_merged_df["object_id"] = _cached_merged_df["object_id"].astype(str)
    _cached_merged_df["cell_info"] = _cached_merged_df.apply(format_cell, axis=1)

    pivot_compact = _cached_merged_df.pivot_table(
        index=["user_id", "username"],
        columns="object_id",
        values="cell_info",
        aggfunc="first"
    ).reset_index()

    # object_id â†’ object_name
    object_mapping = _cached_merged_df.set_index("object_id")["object_name"].to_dict()

    # ã‚«ãƒ©ãƒ ã®å†æ§‹ç¯‰
    new_columns = ["user_id", "username"] + list(pivot_compact.columns[2:])
    pivot_compact.columns = new_columns

    # ã‚«ãƒ©ãƒ ã®ã†ã¡æ•°å­—ï¼ˆobject_idï¼‰ã ã‘å–ã‚Šå‡ºã—ã€ãã‚Œã‚’ã‚½ãƒ¼ãƒˆ
    valid_columns = [col for col in pivot_compact.columns[2:] if col.isdigit()]
    missing_keys = [obj for obj in valid_columns if obj not in object_mapping]
    if missing_keys:
        print(f"âš ï¸ object_mapping ã«å­˜åœ¨ã—ãªã„ã‚­ãƒ¼: {missing_keys}")

    pivot_compact["user_id"] = pivot_compact["user_id"].astype(int)
    pivot_compact = pivot_compact.sort_values(by="user_id")
    # ã‚½ãƒ¼ãƒˆå¾Œã«å†åº¦æ–‡å­—åˆ—å‹ã«æˆ»ã™ï¼ˆå¿…è¦ã§ã‚ã‚Œã°ï¼‰
    pivot_compact["user_id"] = pivot_compact["user_id"].astype(str)

    ordered_object_names = sorted(object_mapping.keys(), key=lambda x: int(x))
    existing_columns = [col for col in ordered_object_names if col in pivot_compact.columns]
    ordered_columns = ["user_id", "username"] + existing_columns
    pivot_compact = pivot_compact[ordered_columns] 

    pivot_compact = pivot_compact.rename(columns=object_mapping)

    # ä½™åˆ†ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã®åˆ—ãªã©ã‚’é™¤ã„ãŸå®Ÿéš›ã® object_name åˆ—ã ã‘ã‚’å–å¾—
    object_name_cols = pivot_compact.columns[2:].tolist()

    # ========== Heatmap (User Similarity) ==========
    # user_similarity ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ•°å€¤é †ã«ã‚½ãƒ¼ãƒˆ
    sorted_index = sorted(user_similarity.index, key=lambda x: int(x))
    user_similarity = user_similarity.loc[sorted_index, sorted_index]

    user_labels = [
        f"{uid} ({_cached_user_dict.get(str(uid), 'Unknown')})" for uid in user_similarity.index
    ]

    fig, ax = plt.subplots(figsize=(10, 8))
    sns.heatmap(
        user_similarity[::-1],
        cmap="coolwarm",
        annot=True,
        fmt=".2f",
        ax=ax,
        xticklabels=user_labels,
        yticklabels=user_labels[::-1]
    )
    plt.xticks(rotation=45, ha="right", fontsize=10)
    plt.yticks(rotation=0, fontsize=10)

    img_buf = BytesIO()
    plt.savefig(img_buf, format="png")
    plt.close(fig)
    img_buf.seek(0)
    heatmap_base64 = base64.b64encode(img_buf.getvalue()).decode("utf-8")

    # ========== ãƒ¦ãƒ¼ã‚¶ãƒ¼é¡ä¼¼åº¦ã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ  ==========
    similarity_values = user_similarity.values.flatten()
    similarity_values = similarity_values[similarity_values < 1.0]
    fig, ax = plt.subplots(figsize=(8, 6))
    sns.histplot(similarity_values, bins=20, kde=True, ax=ax)
    ax.set_xlabel("User Similarity", fontsize=12)
    ax.set_ylabel("é »åº¦", fontsize=12)
    ax.set_title("Histogram of User Similarity", fontsize=14)
    plt.xticks(fontsize=10)
    plt.yticks(fontsize=10)
    img_buf = BytesIO()
    plt.savefig(img_buf, format="png", bbox_inches="tight")
    plt.close(fig)
    img_buf.seek(0)
    similarity_hist_base64 = base64.b64encode(img_buf.getvalue()).decode("utf-8")

    # ã¾ãšã€æœ€æ–°ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã‚’å–å¾—ã™ã‚‹é–¢æ•°ã‚’å®šç¾©
    def update_user_info_from_csv():
        user_df = pd.read_csv(USERS_FILE, encoding="utf-8-sig", dtype={"user_id": str})
        return dict(zip(user_df["user_id"], user_df["username"]))

    # get_username() ã‚‚æœ€æ–°ã® _cached_user_dict ã‚’ä½¿ã†ã‚ˆã†ã«å®šç¾©
    def get_username(user_id):
        # user_id ã‚’æ–‡å­—åˆ—ã«ã—ã¦ã‹ã‚‰è¾æ›¸å‚ç…§ã™ã‚‹ã“ã¨ã§ç¢ºå®Ÿã«å–å¾—
        return _cached_user_dict.get(str(user_id), "Unknown")

    # ========== ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚° ==========
    # ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ç›´å‰ã«ã€æœ€æ–°ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã§ _cached_user_dict ã‚’æ›´æ–°
    _cached_user_dict = update_user_info_from_csv()
    # PCA + KMeans
    num_users = user_similarity.shape[0]
    num_clusters = max(2, int(num_users / 4) + 1)  #ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æ•°ã®æ±ºå®šãƒ«ãƒ¼ãƒ«ï¼ˆå¹³å‡4äººã«ãªã‚‹ã‚ˆã†ã«åˆ†å‰²ï¼‰

    if isinstance(user_similarity, np.ndarray):
        user_similarity_df = pd.DataFrame(
            user_similarity,
            index=_cached_user_dict.keys(),
            columns=_cached_user_dict.keys()
        )
    else:
        user_similarity_df = user_similarity

    pca = PCA(n_components=2)
    user_embedding = pca.fit_transform(user_similarity_df)
    user_ids = list(user_similarity_df.index)

    kmeans = KMeans(n_clusters=num_clusters, random_state=42, n_init=10)
    clusters = kmeans.fit_predict(user_embedding)

    cluster_df = pd.DataFrame({
        "user_id": [str(uid) for uid in user_ids],
        "username": [get_username(uid) for uid in user_ids],
        "cluster": clusters + 1
    }).sort_values(["cluster"], ascending=True).sort_values(["username"], key=lambda x: x.str.casefold())

    fig, ax = plt.subplots(figsize=(8, 6))
    colors = ["red", "blue", "green", "purple", "orange", "cyan", "magenta", "brown"]
    num_colors = min(num_clusters, len(colors))

    for cluster_id in range(kmeans.n_clusters):
        cluster_users = cluster_df[cluster_df["cluster"] == cluster_id + 1]
        indices = cluster_users.index.to_numpy()
        cluster_points = user_embedding[indices, :2]

        ax.scatter(
            cluster_points[:, 0], cluster_points[:, 1],
            label=f"Cluster {cluster_id + 1}",
            alpha=0.6,
            color=colors[cluster_id % len(colors)]
        )
        for (x, y), username in zip(cluster_points, cluster_users["username"]):
            ax.text(x, y, username, fontsize=10, ha='right', va='bottom', color="black")

        # ã‚¯ãƒ©ã‚¹ã‚¿æ¥•å††
        if len(cluster_points) > 1:
            x_mean, y_mean = cluster_points[:, 0].mean(), cluster_points[:, 1].mean()
            cov = np.cov(cluster_points, rowvar=False)
            # å¯¾ç§°è¡Œåˆ—ãªã®ã§ eigh ã‚’åˆ©ç”¨ï¼ˆå›ºæœ‰å€¤ã¯æ˜‡é †ã«è¿”ã‚‹ï¼‰
            eigenvals, eigenvecs = np.linalg.eigh(cov)
            order = eigenvals.argsort()[::-1]
            eigenvals = eigenvals[order]
            eigenvecs = eigenvecs[:, order]
            # 95%ä¿¡é ¼æ¥•å††ã®ãŸã‚ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å› å­
            confidence_level = 0.95
            chi2_val = np.sqrt(chi2.ppf(confidence_level, df=2))
            # å¹…ã¨é«˜ã•ï¼ˆæ¥•å††ã®é•·è»¸ãƒ»çŸ­è»¸ã¯2å€ã®æ¨™æº–åå·®Ã—ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å› å­ï¼‰
            width = 2 * chi2_val * np.sqrt(eigenvals[0])
            height = 2 * chi2_val * np.sqrt(eigenvals[1])
            # å›è»¢è§’åº¦ã¯ arctan2 ã‚’ç”¨ã„ã¦è¨ˆç®—
            angle = np.degrees(np.arctan2(eigenvecs[1, 0], eigenvecs[0, 0]))

            ell = Ellipse(
                xy=(x_mean, y_mean),
                width=width,
                height=height,
                angle=angle,
                edgecolor=colors[cluster_id % len(colors)],
                facecolor="none",
                linewidth=2
            )
            ax.add_patch(ell)
        elif len(cluster_points) == 1:
            x, y = cluster_points[0]
            ell = Ellipse(
                xy=(x, y),
                width=0.2,
                height=0.2,
                edgecolor=colors[cluster_id % len(colors)],
                facecolor="none",
                linewidth=2,
                linestyle="dashed"
            )
            ax.add_patch(ell)

    ax.set_xlabel("PCA Component 1")
    ax.set_ylabel("PCA Component 2")
    ax.set_title("User Clustering Visualization")
    ax.legend()
    img_buf = BytesIO()
    plt.savefig(img_buf, format="png")
    plt.close(fig)
    img_buf.seek(0)
    cluster_plot_base64 = base64.b64encode(img_buf.getvalue()).decode("utf-8")

    # ========== æ¨è–¦ã‚¹ã‚³ã‚¢ã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ  ==========
    recommendation_scores = _cached_recommend_df["recommendation_score"].dropna()
    fig, ax = plt.subplots(figsize=(8, 6))
    sns.histplot(recommendation_scores, bins=20, kde=True, ax=ax)
    ax.set_xlabel("Recommendation Score")
    ax.set_ylabel("Frequency")
    ax.set_title("Histogram of Recommendation Scores")
    img_buf = BytesIO()
    plt.savefig(img_buf, format="png")
    plt.close(fig)
    img_buf.seek(0)
    recommendation_hist_base64 = base64.b64encode(img_buf.getvalue()).decode("utf-8")

    # å¿…è¦ãªæƒ…å ±ã‚’ã¾ã¨ã‚ã¦è¿”ã™
    return (
        heatmap_base64,
        similarity_hist_base64,
        cluster_df,
        cluster_plot_base64,
        recommendation_hist_base64,
        pivot_compact,
        object_name_cols
    )
